clients:
  - name: "default_client"
    type: "openai"
    config:
      apiKey: "${OPENAI_API_KEY}"
      model: "gpt-3.5-turbo"
    default: true

flows:
  - name: "mcp_example_flow"
    clientName: "default_client"
    steps:
      # Step 1: Initialize the MCP session
      - name: "initialize_mcp"
        executor:
          type: "mcp"
          withconfig:
            endpoint: "http://localhost:8080"
            transport: "http"
            outputToContext: true

      # Step 2: Read a resource from the MCP server
      - name: "read_resource"
        executor:
          type: "mcp"
          withconfig:
            endpoint: "http://localhost:8080"
            transport: "http"
            resourceUri: "/resources/documents/${documentId}"
            outputToContext: true
            resultVarName: "document"

      # Step 3: Call a tool on the MCP server with arguments from variables
      - name: "call_tool"
        executor:
          type: "mcp"
          withconfig:
            endpoint: "http://localhost:8080"
            transport: "http"
            toolName: "summarize"
            toolArgVars: ["document"]
            outputToContext: true
            resultVarName: "summary"

      # Step 4: Use LLM to analyze the results
      - name: "analyze_results"
        executor:
          type: "llm"
          withconfig:
            template: |
              You are analyzing data retrieved from an MCP server.

              The document content is:
              ${document}

              The summary is:
              ${summary}

              Please provide your insights on this information:
            outputJSON: false

    # Define flow variables with default values
    variables:
      documentId: "example-doc-1"
